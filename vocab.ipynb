{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOCABUOLARY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution_event_id": "7c34952c-825a-4047-a325-1beb37fd018b",
    "last_executed_text": "# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token\n\nclass Vocabulary:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n        self.num_words = 3  # Count SOS, EOS, PAD\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.num_words\n            self.word2count[word] = 1\n            self.index2word[self.num_words] = word\n            self.num_words += 1\n        else:\n            self.word2count[word] += 1\n\n    # Remove words below a certain count threshold # CHANGE probably shouldn't do this\n    def trim(self, min_count):\n        keep_words = []\n        for k, v in self.word2count.items():\n            if v >= min_count:\n                keep_words.append(k)        \n        print('keep_words {} / {} = {:.4f}'.format(\n            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n        ))\n        # Reinitialize dictionaries\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n        self.num_words = 3 # Count default tokens\n\n        for word in keep_words:\n            self.addWord(word)",
    "persistent_id": "c0c8b32c-c6f2-4b5d-b734-9d367e589a73"
   },
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "EOC_token = 3 # end of correct answer\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {'eoc': EOC_token}\n",
    "        self.word2count = {'eoc': 0}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\", EOC_token: \"eoc\"}\n",
    "        self.num_words = 4  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold # CHANGE probably shouldn't do this\n",
    "    def trim(self, min_count):\n",
    "        keep_words = []\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)        \n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\", EOC_token: \"eoc\"}\n",
    "        self.num_words = 4 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution_event_id": "9671fa40-de6b-4b82-87a7-eab68a7268f5",
    "last_executed_text": "# make data simple\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )",
    "persistent_id": "1f603aa4-239e-4824-b50b-b6be545e7972"
   },
   "outputs": [],
   "source": [
    "# make data simple\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution_event_id": "e6042e5b-d2c2-4be0-9c05-d9a3fcb8c964",
    "last_executed_text": "# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    s = re.sub(r\"\\s+\", r\" \", s).strip()\n    return s",
    "persistent_id": "5b90b860-418b-4dae-a2c7-624ae3fa89eb"
   },
   "outputs": [],
   "source": [
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_prep(s):\n",
    "    rv = s.split()[1]\n",
    "    if rv == 'di' or rv == 'in':\n",
    "        return s.split()[2]\n",
    "    else:\n",
    "        return rv\n",
    "    \n",
    "def simplify_color(s):\n",
    "    return s\n",
    "\n",
    "def simplify_obj(s):\n",
    "    s = normalizeString(s)   \n",
    "    if len(s.split()) > 1:\n",
    "        return s.split()[1]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "#only keep first x exchanges, return pastconvo\n",
    "def shorten_pastconvo(pastconvo_one, exchanges):\n",
    "    numexchange = pastconvo_one.count('Tutor:')\n",
    "    if numexchange > exchanges:\n",
    "        return \"Tutor:\".join(pastconvo_one.split(\"Tutor:\", exchanges+1)[:exchanges+1])\n",
    "    else:\n",
    "        return pastconvo_one\n",
    "\n",
    "#added correct and translations\n",
    "def construct_pastconvo(xy, exchanges, translations):\n",
    "    pastconvo = []\n",
    "    for i in range(len(xy)):\n",
    "        pastconvo_one = shorten_pastconvo(xy['Past Convo'][i], exchanges)\n",
    "        p = xy['Prep'][i]\n",
    "        o = xy['Obj'][i]\n",
    "        c = xy['Color'][i]\n",
    "        eoc = 'EOC'\n",
    "        pt = translations[simplify_prep(p)]\n",
    "        ot = translations[simplify_obj(o)]\n",
    "        ct = translations[simplify_color(c)]\n",
    "        \n",
    "        pastconvo.append(' '.join([p,o,c, pt,ot,ct, eoc, pastconvo_one]))\n",
    "    return pastconvo\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
