{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import itertools\n",
    "import math\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leave out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data selected\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 2500\n",
    "\n",
    "\n",
    "xy = pd.read_csv('./prep_student_input.csv')\n",
    "z = pd.read_csv('./word_translations.csv')\n",
    "\n",
    "translations = {z['Italian'][i]: z['English'][i] for i in range(len(z))}\n",
    "\n",
    "randomindexes = [random.randint(0, INPUT_SIZE) for _ in range(INPUT_SIZE)]\n",
    "\n",
    "prep = [xy['Prep']]\n",
    "\n",
    "pastconvo = [xy['Prep'][randomindexes[i]]+' '+xy['Obj'][randomindexes[i]] +' '+ xy['Color'][randomindexes[i]] +' '+ xy['Past Convo'][randomindexes[i]] for i in range(len(randomindexes))]\n",
    "\n",
    "response = [xy['Tutor Response'][randomindexes[i]] for i in range(len(randomindexes))]\n",
    "\n",
    "\n",
    "#' '.join(pastconvo[i].split()[TOKENS_TAKEN:])\n",
    "pairs = [[pastconvo[i], response[i]] for i in range(len(pastconvo))]\n",
    "\n",
    "print(\"input data selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOCABUOLARY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold # CHANGE probably shouldn't do this\n",
    "    def trim(self, min_count):\n",
    "        keep_words = []\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)        \n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data simple\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counted words: 1014\n",
      "vocabulary created\n"
     ]
    }
   ],
   "source": [
    "pairs = [[normalizeString(line) for line in p] for p in pairs]\n",
    "\n",
    "\n",
    "pastwhole = pd.DataFrame(data=xy['Past Convo']).values.flatten().tolist()\n",
    "tutorwhole = pd.DataFrame(data=xy['Tutor Response']).values.flatten().tolist()\n",
    "\n",
    "pairs_whole = [[pastwhole[i], tutorwhole[i]] for i in range(len(pastwhole))]\n",
    "\n",
    "pairs_whole = [[normalizeString(line) for line in p] for p in pairs_whole]\n",
    "\n",
    "voc = Vocabulary(\"dialog\")\n",
    "\n",
    "\n",
    "\n",
    "#getting  rid of rare words\n",
    "for pair in pairs_whole:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "print(\"counted words:\", voc.num_words)\n",
    "print(\"vocabulary created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make column consistent and transpose\n",
    "def zeroPadding(l, fillvalue= 0):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryMatrix(l, value=0):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        \n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len, input_batch, output_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention using dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words, scores\n",
    "\n",
    "\n",
    "#returns a list of output words fiven a input sentence\n",
    "def evaluateInput(encoder, decoder, searcher, voc, input_sentence, max_length):\n",
    "    input_sentence = normalizeString(input_sentence)\n",
    "    # Evaluate sentence\n",
    "    output_words, scores = evaluate(encoder, decoder, searcher, voc, input_sentence, max_length)\n",
    "    # Format and print response sentence\n",
    "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "    return output_words, scores\n",
    "#     print('Bot:', ' '.join(output_words))\n",
    "\n",
    "def evaluate_with_target(encoder, decoder, searcher, voc, TEST_SIZE, INPUT_SIZE):\n",
    "\n",
    "    randomindexes = [random.randint(INPUT_SIZE, len(xy['Past Convo'])) for _ in range(TEST_SIZE)]\n",
    "\n",
    "    inputs = [xy['Past Convo'][randomindexes[i]] for i in range(TEST_SIZE)]\n",
    "    targets = [xy['Tutor Response'][randomindexes[i]] for i in range(TEST_SIZE)]\n",
    "\n",
    "    for i in range(TEST_SIZE):\n",
    "        max_length = len(normalizeString(targets[i]).split()) \n",
    "        print(\"past convo:\", inputs[i])\n",
    "        print(\"\\n\")\n",
    "\n",
    "        output_words, scores = evaluateInput(encoder, decoder, searcher, voc, inputs[i], max_target_len)\n",
    "        print('Bot:', ' '.join(output_words))\n",
    "        print(\"\\n\")\n",
    "        print(\"Correct: \", targets[i])\n",
    "        print(\"\\n\")\n",
    "        \n",
    "def validation_eval(encoder, decoder, searcher, voc, TEST_SIZE, INPUT_SIZE):\n",
    "\n",
    "    randomindexes = [random.randint(INPUT_SIZE, len(xy['Past Convo'])) for _ in range(TEST_SIZE)]\n",
    "\n",
    "    inputs = [xy['Past Convo'][randomindexes[i]] for i in range(TEST_SIZE)]\n",
    "    targets = [xy['Tutor Response'][randomindexes[i]] for i in range(TEST_SIZE)]\n",
    "    \n",
    "    scores = []  \n",
    "    for i in range(TEST_SIZE):\n",
    "        max_length = len(normalizeString(targets[i]).split()) \n",
    "        print(\"past convo:\", inputs[i])\n",
    "        print(\"\\n\")\n",
    "\n",
    "        output_words, scorelist = evaluateInput(encoder, decoder, searcher, voc, inputs[i], max_target_len)\n",
    "        scores.append(sum(scorelist))\n",
    "        print('Bot:', ' '.join(output_words))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    return sum(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simulated student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pprint\n",
    "pp = pprint.PrettyPrinter(indent = 4)\n",
    "\n",
    "\n",
    "z = pd.read_csv('./word_translations.csv')\n",
    "translations = {z['Italian'][i]: z['English'][i] for i in range(len(z))}\n",
    "translations_toItalian = {z['English'][i]: z['Italian'][i] for i in range(len(z))}\n",
    "\n",
    "concepts = list(translations.keys())\n",
    "prep = concepts[:8]\n",
    "color = concepts[8:16]\n",
    "obj = concepts[16:]\n",
    "\n",
    "def concept(word):\n",
    "    if iseng(word):\n",
    "        return translations_toItalian[word]\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "def iseng(word):\n",
    "    if word in translations_toItalian.keys():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def isitalian(word):\n",
    "    if word in translations.keys():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#guess is list in correct order, correct is solution list\n",
    "def identify_incorrects(guess, correct):\n",
    "    rv = []\n",
    "    for i in range(len(correct)):\n",
    "        if guess[i] != correct[i]:\n",
    "            rv.append(correct[i])\n",
    "    return rv\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#correct order is prep obj color\n",
    "\n",
    "\n",
    "class Student:\n",
    "    def __init__(self, pickup, forget):\n",
    "        global prep,color,obj\n",
    "        self.pickup = pickup\n",
    "        self.forget = forget\n",
    "        self.knowledge = {\n",
    "            \"prep\": {p: random.random() for p in prep},\n",
    "            \"color\": {c: random.random() for c in color},\n",
    "            \"obj\": {o: random.random() for o in obj}\n",
    "        }\n",
    "       \n",
    "    #TODO: can output random italian word too\n",
    "    #output three words in correct order list\n",
    "    def guess(self, correct):\n",
    "        global translations\n",
    "        #correct: [prep, object, color]\n",
    "        prep_c, obj_c, color_c = correct\n",
    "        prep_t = translations[prep_c]\n",
    "        obj_t = translations[obj_c]\n",
    "        color_t = translations[color_c]\n",
    "        \n",
    "#         rv = 'is it '\n",
    "        rv = []\n",
    "        rv.append(prep_c) if self.knowledge[\"prep\"][prep_c] > 0.7 else rv.append(prep_t)\n",
    "        rv.append(obj_c)  if self.knowledge[\"obj\"][obj_c] > 0.7 else rv.append(obj_t)\n",
    "        rv.append(color_c) if self.knowledge[\"color\"][color_c] > 0.7 else rv.append(color_t)\n",
    "        return rv\n",
    "    \n",
    "    #returns empty string if nothing to ask\n",
    "    #returns the eng word\n",
    "    def ask(self, correct):\n",
    "        #TODO: randomize order\n",
    "        #correct = [prep_c, obj_c, color_c]\n",
    "        global translations\n",
    "        word = ''\n",
    "        prep_c, obj_c, color_c = correct\n",
    "        \n",
    "        if self.knowledge[\"prep\"][prep_c] < 0.3:\n",
    "            word = prep_c\n",
    "        elif self.knowledge[\"obj\"][obj_c] <  0.3:\n",
    "            word = obj_c\n",
    "        elif self.knowledge[\"color\"][color_c] < 0.3:\n",
    "            word = color_c\n",
    "        \n",
    "        if word != '':\n",
    "            #rv = 'How do i say ' + translations[word] + ' in Italian'\n",
    "            rv = translations[word]\n",
    "        else:\n",
    "            rv = ''\n",
    "        return rv\n",
    "    #forgets concepts that is not mentioned for each tutor response, excluding  gained\n",
    "#     def forget(self, gained):\n",
    "        \n",
    "    def pickout_concepts(self, output_words):\n",
    "        #return all concepts (only in italian)\n",
    "        rv = []\n",
    "        for word in output_words:\n",
    "            if isitalian(word):\n",
    "                rv.append(word)\n",
    "            elif iseng(word):\n",
    "                rv.append(concept(word))\n",
    "        return list(set(rv))\n",
    "    \n",
    "    def pickout_relevent_concepts(self, output_words, correct):\n",
    "        #all concepts in italian\n",
    "        concepts = self.pickout_concepts(output_words)\n",
    "        return [x for x in concepts if x in correct]\n",
    "                \n",
    "    def change_knowledge(self, output_words, correct):\n",
    "        #pick out knowledge\n",
    "        global prep,color,obj\n",
    "        concepts = self.pickout_relevent_concepts(output_words, correct)\n",
    "        p = []\n",
    "        o = []\n",
    "        c=  []\n",
    "        for word in concepts:\n",
    "            if word in prep:\n",
    "                p.append(word)\n",
    "            elif word in color:\n",
    "                c.append(word)\n",
    "            elif word in obj:\n",
    "                o.append(word)\n",
    "        order = [\"prep\", \"obj\", \"color\"]  \n",
    "        groups = [p, o, c]\n",
    "        change = 0\n",
    "        \n",
    "        #update knowledge and return change\n",
    "        #TODO only forget things that are not mentioned \n",
    "        for i in range(3):\n",
    "            for c in groups[i]:\n",
    "                if self.knowledge[order[i]][c] < 1:\n",
    "                    self.knowledge[order[i]][c] = 1\n",
    "                    change +=1\n",
    "#                     if random.random() < self.pickup: \n",
    "#                         self.knowledge[order[i]][c] = min(self.knowledge[order[i]][c]+0.4, 1)\n",
    "#                         change += 1   \n",
    "\n",
    "        return change\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def penalty(output_words, student, studentexpect, correct, incorrects):\n",
    "    concepts = student.pickout_concepts(output_words)\n",
    "    relevent = student.pickout_relevent_concepts(output_words, correct)\n",
    "    #TODO relevent includes english and italian\n",
    "    \n",
    "    #if nothing correct but confirmed could be because ordering or grammar\n",
    "    \n",
    "    #conditional on student answer\n",
    "    # 1 => penalize\n",
    "    # 0 => reward\n",
    "    \n",
    "    #incorrect = list incorrect concepts in italian\n",
    "    if len(incorrects) == 0 and studentexpect == '':\n",
    "        if 'correct' not in output_words or 'yes' not in output_words:\n",
    "            print(\"penalize: student was correct but no confirmation\")\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"reward: correct\")\n",
    "            return 0.2\n",
    "    elif studentexpect != '':\n",
    "        #TODO need both eng and italian \n",
    "        if studentexpect in relevent:\n",
    "            print(\"reward: answered question\")\n",
    "            return 0.2\n",
    "        else:\n",
    "            print(\"penalize: didn't answer question\")\n",
    "            return 1\n",
    "    else:\n",
    "        #the student made a guess that's incorrect \n",
    "        if len(incorrects) == 3 and 'correct' in output_words:\n",
    "            print(\"penalize: all wrong but said correct\")\n",
    "            return 1\n",
    "        if concepts == []:\n",
    "            #maybe made a grammar hint\n",
    "            print(\"neutral: did not make a word hint\")\n",
    "            return 0.8\n",
    "        elif len(concepts) != len(relevent):\n",
    "            print(\"penalize: had irrelevent hints\")\n",
    "            return 1\n",
    "        else:\n",
    "            #needs to be a hint that student got incorrect\n",
    "            for hint in relevent:\n",
    "                if hint not in incorrects:\n",
    "                    print(\"penalize: not a hint that student got wrong\")\n",
    "                    return 1\n",
    "            print(\"reward: is a hint student got wrong\")\n",
    "            return 0.2\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start one eval\n",
    "def simulate_with_student(encoder, decoder, searcher, voc):\n",
    "# one conversation\n",
    "    student = Student(1,0)\n",
    "    tutor_score = 0\n",
    "    studentexpect = ''\n",
    "    guess_incorrects = []\n",
    "    prep_c =  random.choice(prep)\n",
    "    color_c = random.choice(color)\n",
    "    obj_c = random.choice(obj)\n",
    "    correct = [prep_c, obj_c, color_c]\n",
    "    print(correct)\n",
    "    \n",
    "    #TODO: while student not correct or expects answer\n",
    "    for i in range(5):\n",
    "        coin = random.random()\n",
    "        if coin < 0.5 and student.ask(correct) != '':\n",
    "            askeng = student.ask(correct)\n",
    "            studentexpect = translations_toItalian[askeng]\n",
    "            input_sent = 'How do you say ' + askeng + ' in Italian'\n",
    "        else:\n",
    "            guess = student.guess(correct)\n",
    "            guess_incorrects = identify_incorrects(guess, correct)\n",
    "            input_sent = \"is it \"+ guess[0] + \" \" + guess[1] + \" \" + guess[2]\n",
    "        \n",
    "        print('\\n')\n",
    "        print('Student:', input_sent)\n",
    "        print('incorrect:', guess_incorrects)\n",
    "        print('expect:', studentexpect)\n",
    "\n",
    "        #evaluate on model\n",
    "        output_words = evaluateInput(encoder, decoder, searcher, voc, input_sent, max_target_len)\n",
    "        output = ' '.join(output_words)\n",
    "        #evaluate on input\n",
    "#         output = input('> ')\n",
    "#         if output == 'q' or output == 'quit': break\n",
    "#         output_words = output.split()\n",
    "        \n",
    "        #how many concpets changed\n",
    "        change = student.change_knowledge(output_words, correct)\n",
    "        \n",
    "        #change tutor score\n",
    "        tutor_score += penalty(output_words, student, studentexpect, correct, guess_incorrects)\n",
    "\n",
    "        print('Bot:', output)\n",
    "        print('pickout concpets:', student.pickout_concepts(output_words))\n",
    "        print('change:', change)\n",
    "        #TODO: tutor_score\n",
    "        print('penalty', tutor_score)  \n",
    "        studentexpect = ''\n",
    "        guess_incorrects = []\n",
    "        \n",
    "    return tutor_score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test train with input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#simulate_with_student(encoder, decoder, searcher, voc)\n",
    "# simulate_with_student(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative log lokelihood loss\n",
    "# maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "def maskNLLLoss(inp, target, mask): \n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    #loss = reward * loss -> 0.001/1\n",
    "#     loss = loss * tutor_score\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[ 32,  32,  32,  ...,  32,  32,  32],\n",
      "        [143, 143,  33,  ...,  33, 135,  66],\n",
      "        [144, 144,  23,  ...,  23, 136,  67],\n",
      "        ...,\n",
      "        [278,   0,   0,  ...,   0,   0,   0],\n",
      "        [ 21,   0,   0,  ...,   0,   0,   0],\n",
      "        [  2,   0,   0,  ...,   0,   0,   0]])\n",
      "lengths: tensor([155, 116, 108,  89,  76,  72,  65,  62,  61,  58,  54,  51,  42,  40,\n",
      "         40,  38,  35,  33,  33,  33,  32,  32,  29,  29,  28,  27,  26,  25,\n",
      "         23,  22])\n",
      "target_variable: tensor([[ 40, 114, 246,  ...,  32,  32,  40],\n",
      "        [  5, 211,  46,  ...,  33, 135, 241],\n",
      "        [127, 129,  13,  ...,   5, 136, 324],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  0,   0,   0,  ...,   0,   0,   0]])\n",
      "mask: tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 72\n",
      "START TRAINING\n",
      "\n",
      "\n",
      " Iteration: 1\n",
      "returned loss 6.916131032274125\n",
      "\n",
      "\n",
      " Iteration: 2\n",
      "returned loss 6.747598032218909\n",
      "\n",
      "\n",
      " Iteration: 3\n",
      "returned loss 6.1268713049369286\n",
      "\n",
      "\n",
      " Iteration: 4\n"
     ]
    }
   ],
   "source": [
    "LEARN_RATE = 0.001\n",
    "clip = 50.0\n",
    "# num_iters = 400\n",
    "DESIRED_LOSS = 0.1\n",
    "\n",
    "small_batch_size = 30\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len, input_batch, output_batch = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)\n",
    "\n",
    "attn_model = 'dot'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model,  embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "#pass models to device \n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "#optimizers\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=LEARN_RATE)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=LEARN_RATE)\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "# start training\n",
    "print(\"START TRAINING\")\n",
    "print(\"\\n\")\n",
    "\n",
    "returned_losses = []\n",
    "\n",
    "iteration = 0\n",
    "# for iteration in range(num_iters):\n",
    "while iteration < 2800:\n",
    "    iteration += 1\n",
    "    \n",
    "    print(\" Iteration:\", iteration)\n",
    "    \n",
    "    batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "    input_variable, lengths, target_variable, mask, max_target_len, input_batch, output_batch = batches\n",
    "    \n",
    "    #train one iter\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "    \n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "#     print(\"encoder output shape\", encoder_outputs.shape)\n",
    "#     print(\"last encoder hidden shape\", encoder_hidden.shape)\n",
    "\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range (small_batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "#     print(\"initial decoder input shape\", decoder_input.shape)\n",
    "#     print(decoder_input)\n",
    "\n",
    "    decoder_hidden =  encoder_hidden[:decoder.n_layers]\n",
    "#     print(\"initial decoder hidden state shape\", decoder_hidden.shape)\n",
    "\n",
    "    for t in range(max_target_len):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #teacher forcing\n",
    "        decoder_input = target_variable[t].view(1,-1)\n",
    "\n",
    "        mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "        loss += mask_loss\n",
    "        print_losses.append(mask_loss.item() * nTotal)\n",
    "\n",
    "        n_totals += nTotal\n",
    "        \n",
    "    #simulated student eval\n",
    "    \n",
    "    if iteration > 300 and iteration % 20 == 0:\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        searcher = GreedySearchDecoder(encoder, decoder)\n",
    "        tutor_score = simulate_with_student(encoder, decoder, searcher, voc)\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        loss = loss * tutor_score / 5\n",
    "        returned_loss = sum(print_losses) / n_totals * tutor_score / 5\n",
    "    else:\n",
    "        returned_loss = sum(print_losses) / n_totals\n",
    "        \n",
    "    loss.backward(retain_graph=True)\n",
    "    \n",
    "    \n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    \n",
    "    returned_losses.append(returned_loss)\n",
    "    \n",
    "    if iteration % 200 == 0:   \n",
    "        plt.plot(returned_losses)\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"returned loss\", returned_loss)\n",
    "#     print(returned_losses)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past convo: Tutor: \"Is In Front Of The\" is \"e di fronte al\". Please try to fill in the blank in Italian.  Student: il cane e di fronte al.  Tutor: Well,  \"bunny\" is  \"coniglio\" Student: What thes word for yellow? I almost have it.  Tutor: Can you try filling in the blank to the best of your ability? Student: il cane e di cronte al coniglio.  Tutor: Can you give me your best guess? Student: il cane e di cronte al coniglio. Is my best guess of how the sentence is suppose to look.  Tutor: Hmm...  \"is in front of the\" is  \"e di fronte al\" Student: il cane e di fronte al coniglio. \n",
      "\n",
      "\n",
      "Bot: the word for yellow or can you try to fill in the blank ? . cane try again . it should be al\n",
      "\n",
      "\n",
      "Correct:  now add yellow, \"giallo\"\n",
      "\n",
      "\n",
      "past convo: Tutor: \"Plant\" is \"pianta\". Please try to fill in the blank in Italian.  Student: Hello? Tutor: alla (\"to the\") is used when the following word (pianta) is feminine and a singular object.  It is a contraction of a (\"to\") and la (\"the\"). When the following word begins with a vowel, this is shortened to all' and prepended to the word. Student: il coniglio alla pianta verde Tutor: Remember what plant is in Italian, is cane Student:  il coniglio alla cane verde\n",
      "\n",
      "\n",
      "Bot: e vecino alla is is not of the words gialla and scatola . ! cane way to say is behind the . also plant is behind and e di fronte alla . now\n",
      "\n",
      "\n",
      "Correct:  Remember, \"is next to the\" is \"e vicino alla\" in Italian.\n",
      "\n",
      "\n",
      "past convo: Tutor: \"Bunny\" is \"coniglio\". Please try to fill in the blank in Italian.  Student: e fronte il greene coniglio\n",
      "\n",
      "\n",
      "Bot: il coniglio e es la scatola giallo . how do you say yellow ? ! ! gialla which is spanish . try to use the phrase as\n",
      "\n",
      "\n",
      "Correct:  \"verde\" is green, remember in Italian it comes AFTER the word you are describing.\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: il cane e all'interno della scatola verde\n",
      "\n",
      "\n",
      "Bot: il cane e di fronte alla . do you know how to say box ? ? . would be cane phrase . it would be scatola gialla .\n",
      "\n",
      "\n",
      "Correct:  \"is inside of the\" is \"e dentro la\" . Try again\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: how do you say 'on top of?'\n",
      "\n",
      "\n",
      "Bot: e di fronte means is in front of . . and remember that adjectives follow the noun . . . . would be cane\n",
      "\n",
      "\n",
      "Correct:  \"Is on top of the\" is \"e in cima al\".\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: How do I say yellow in Italian?\n",
      "\n",
      "\n",
      "Bot: i ll give you a hint . bunny is il coniglio . . would be before the word letto . with a vowel . it is a contraction\n",
      "\n",
      "\n",
      "Correct:  \"Yellow\" is \"giallo\". Now, how do you say bunny?\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: La borsa e dietro la gialla scatola. Tutor: Okay, I'll give you a hint.  \"is in front of the\" is  \"e di fronte alla\" Student: How to say \"purple\" in Italian? Tutor: OK,  \"purple\" is \"viola\" Student: La borsa e di fronte la viola scatola. Tutor: ['alla (\"to the\") is used when the following word (scatola) is feminine and a singular object.  It is a contraction of a (\"to\") and la (\"the\"). When the following word begins with a vowel, this is shortened to all\\' and prepended to the word.', 'Words in Italian have a gender associated with them (either masculine or feminine), even when the word is an object, concepts, or abstract ideas.  '] Student: I understand.\n",
      "\n",
      "\n",
      "Bot: ! alla is feminine . also plant is pianta . it is a contraction of the words a to and il the so change il to al and you are correct\n",
      "\n",
      "\n",
      "Correct:  Remember the color follows the noun it describes. How should you change your previous answer? \n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: What is the word for yellow? Tutor: Hmm...  \"yellow\" is \"gialla\" Student: il gatto all in fronte a scatola gialla? Tutor: Hmm...  \"is behind the\" is  \"e dietro la\" Student: Oh, my mistake. Tutor: gialla is the feminine form, because the noun it modifies (scatola) is feminine. Student: Il gato e dentro la scatola gialla? Tutor: Prepositional phrases separate the two noun phrases. Student: Can you give me an example?\n",
      "\n",
      "\n",
      "Bot: no . i find try again . is a contraction of the words a to and il the so change il to al and you are correct . again . it would\n",
      "\n",
      "\n",
      "Correct:  \"E deitro la\" is a prepositional phrase, and it comes between the two noun phrases, \"il gatto\" and \"scatola gialla.\"\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: What is the word for yellow?\n",
      "\n",
      "\n",
      "Bot: the word for box is scatola . remember it s e di fronte alla . . and remember to indicate next to . ! .\n",
      "\n",
      "\n",
      "Correct:  Hmm. The word for \"yellow\" is \"gialla\". Can you try a guess?\n",
      "\n",
      "\n",
      "past convo: Tutor: \"Plant\" is \"pianta\". Please try to fill in the blank in Italian.  Student: Hello? Tutor: alla (\"to the\") is used when the following word (pianta) is feminine and a singular object.  It is a contraction of a (\"to\") and la (\"the\"). When the following word begins with a vowel, this is shortened to all' and prepended to the word. Student: il coniglio alla pianta verde Tutor: Remember what plant is in Italian, is cane Student:  il coniglio alla cane verde\n",
      "\n",
      "\n",
      "Bot: e vecino alla is is not of the words gialla and scatola . ! cane way to say is behind the . also plant is behind and e di fronte alla . now\n",
      "\n",
      "\n",
      "Correct:  Ok, remember that \"is next to the\" is \"e vicino alla\".\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: la painta el accanto la coniglio Tutor: Bunny is coniglio and bunny is cane. Please try again Student: la painta el accanto la coniglio roja\n",
      "\n",
      "\n",
      "Bot: how do you say is behind the ? . cane try again . again . another try again . . again .\n",
      "\n",
      "\n",
      "Correct:  Remember that red is \"rosso.\"\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: la painta el accanto la coniglio Tutor: Bunny is coniglio and bunny is cane. Please try again Student: la painta el accanto la coniglio roja\n",
      "\n",
      "\n",
      "Bot: how do you say is behind the ? . cane try again . again . another try again . . again .\n",
      "\n",
      "\n",
      "Correct:  Remember that red is \"rosso.\"\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: e si cima ell yellow table Tutor: Hmm...  \"is on top of the\" is  \"e in cima al\" Student: e in cima al and yellow table Tutor: Okay, I'll give you a hint.  \"table\" is  \"tavolo\" Student: e in cima al tavolo yeller Tutor: Remember that  \"table\" is \" tavolo\" Student: e in cima al tavolo?\n",
      "\n",
      "\n",
      "Bot: great ! what gender everything is i just think of the the as part of the noun . . . .\n",
      "\n",
      "\n",
      "Correct:  Almost.  Remember yellow is giallo.\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: what is the word for box? Tutor: OK,  box is  scatola Student: what is the word for pink? Tutor: OK,  pink is rosa Student: what is the word for in front of?\n",
      "\n",
      "\n",
      "Bot: it s be e di fronte all albero . ! ! . ! . is a contraction of al to and l the and\n",
      "\n",
      "\n",
      "Correct:  OK, we can break this down one by one. In front of is di fronte.\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: what is \"is under\" in Italian? Tutor: OK,  \"is under the\" is \"e sotto il\" Student: OK, thanks. What is blue table in Italian?\n",
      "\n",
      "\n",
      "Bot: purple sounds like this like english . . to fill in the blank . ! all albero rosa and cat . it is a contraction of the\n",
      "\n",
      "\n",
      "Correct:  Table is tavolo in Italian. Do you know the word for blue in Italian?\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: How do you say next to again? Tutor: Well,  \"is next to the\" is \"e accanto al\" Student: Is it e accanto al camo verde? Tutor: Why don't you try filling in what you can. Student: Okay. e accanto al bed verde?\n",
      "\n",
      "\n",
      "Bot: the rest of the word here . it would be scatola before . . is a contraction of al to and l the and adjectives such as color words follow the noun\n",
      "\n",
      "\n",
      "Correct:  Not bad, now try to remember how to say bed.\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: How do you say is under in Italian? Tutor: Remember that  \"is under the\" is \"e sotto il\" Student: Ok thanks. What is the word for table in Italian? Tutor: ['il (\"the\") is used for when the following word (tavolo) is masculine.', 'Words in Italian have a gender associated with them (either masculine or feminine), even when the word is an object, concepts, or abstract ideas.'] Student: Ok. How do you say table in Italian?\n",
      "\n",
      "\n",
      "Bot: purple in italian . is a contraction of the words a to and il the . . both l albero . is a contraction of the words a to and\n",
      "\n",
      "\n",
      "Correct:  Tavolo\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: la painta el accanto la coniglio Tutor: Bunny is coniglio and bunny is cane. Please try again Student: la painta el accanto la coniglio roja\n",
      "\n",
      "\n",
      "Bot: how do you say is behind the ? . cane try again . again . another try again . . again .\n",
      "\n",
      "\n",
      "Correct:  You're a little off about the phrase for \"is next to the\" and red is rosso.\n",
      "\n",
      "\n",
      "past convo: Tutor: \"Is In Front Of The\" is \"e di fronte al\". Please try to fill in the blank in Italian.  Student: OK. I'll try. Tutor: Hmm...  \"is in front of the\" is \"e di fronte al\" Student: what is the word for bed? Tutor: Great, now do you remember how to say pink? Student: I don't know the word for bed.\n",
      "\n",
      "\n",
      "Bot: the door to say is behind the and you will be right on target . again . . would be cane in this situation . what gender\n",
      "\n",
      "\n",
      "Correct:  Let's go over the word for pink first.\n",
      "\n",
      "\n",
      "past convo: Tutor: \"Plant\" is \"pianta\". Please try to fill in the blank in Italian.  Student: Hello? Tutor: alla (\"to the\") is used when the following word (pianta) is feminine and a singular object.  It is a contraction of a (\"to\") and la (\"the\"). When the following word begins with a vowel, this is shortened to all' and prepended to the word. Student: il coniglio alla pianta verde\n",
      "\n",
      "\n",
      "Bot: e di fronte alla is not needed . how do you say is behind the ? and use all because the cat is next to the tree . again ?\n",
      "\n",
      "\n",
      "Correct:  So close! Do you know how to say \"is next to the\"?\n",
      "\n",
      "\n",
      "past convo: Tutor: \"Blue\" is \"blu\". Please try to fill in the blank in Italian.  Student: What is bunny? Tutor: so how would you say \"blue bunny\"? Student: blu benno?\n",
      "\n",
      "\n",
      "Bot: e dentro la is inside of the . . it would be e vicino alla pianta albero . so remember that is next to the . now try to fill in the blank\n",
      "\n",
      "\n",
      "Correct:  Almost! Bunny is coniglio.\n",
      "\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: il coniglio e dietro el boxo Tutor: Well,  \"is behind the\" is  \"e dietro la\" Student: il coniglio e dietro la boxo\n",
      "\n",
      "\n",
      "Bot: good but what is the word for purple ? ! does not belong in this sentence . again . it would be e di fronte alla . . also\n",
      "\n",
      "\n",
      "Correct:  You're getting there. Box is \"scatola\" and remember, the word for green will come AFTER the word for box. Give it a try.\n",
      "\n",
      "\n",
      "past convo: Tutor: \"Is Behind The\" is \"e dietro la\". Please try to fill in the blank in Italian.  Student: How to say \"yellow box\" in Italian?\n",
      "\n",
      "\n",
      "Bot: i ll give you a hint . box would be scatola . scatola would go before the word yellow . do you remember the word for yellow ?\n",
      "\n",
      "\n",
      "Correct:  Well, \"yellow\" is \"gialla\" and \"box\" is \"scatola\". Can you fill in the blank now?\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: what is the word for yellow bunny?\n",
      "\n",
      "\n",
      "Bot: i ll give you a hint ? . is a contraction of al to and il the . . . . would\n",
      "\n",
      "\n",
      "Correct:  giallo coninglio\n",
      "\n",
      "\n",
      "past convo: Tutor: \"Is In Front Of The\" is \"e di fronte alla\". Please try to fill in the blank in Italian.  Student: OK, and how is it called the blue box? Tutor: Okay, I'll give you a hint.  \"box\" is  \"scatola\" Student: I remember that word, but I don't know the word for blue!? Tutor: Hmm...  \"blue\" is \"blu\" Student: Yes, I remember learning that!\n",
      "\n",
      "\n",
      "Bot: good . now please try to fill in the blank again . ! cane keep that in mind . would be scatola gialla . . again . again\n",
      "\n",
      "\n",
      "Correct:  \n",
      "Then please type in the Italian  'blue box'.\n",
      "\n",
      "\n",
      "past convo: Tutor: Is In Front Of The is e di fronte alla. Please try to fill in the blank in Italian.  Student: what is the word for in front of?\n",
      "\n",
      "\n",
      "Bot: e dietro la . cane it ends in o and use all because the cat is next to the tree . ! all albero rosa\n",
      "\n",
      "\n",
      "Correct:  it is  di fronte alla\n",
      "\n",
      "\n",
      "past convo: Tutor: \"Red\" is \"rosso\". Please try to fill in the blank in Italian.  Student: red is rosso Tutor: Okay, I'll give you a hint.  \"is in front of the\" is  \"e di fronte\" Student: e di fronte\n",
      "\n",
      "\n",
      "Bot: ok now can you try to put it together ? meaning is a contraction of the words a to and il the . also adjectives such as color words follow the noun they\n",
      "\n",
      "\n",
      "Correct:  And how do you say tree in Italian?\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: il cane e all'interno della scatola verde Tutor: Remember that  \"green\" is \"verde\" Student: il cane e allinterno della scatola verde\n",
      "\n",
      "\n",
      "Bot: how do you say is in front of ? . again . it would be scatola gialla . ! cane way to\n",
      "\n",
      "\n",
      "Correct:  e dentro la\" is how to say \"is inside the\"\n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: How do you say bag?\n",
      "\n",
      "\n",
      "Bot: i ll give you a hint . bunny is il coniglio . . would be before the word letto . with a vowel . it is a contraction\n",
      "\n",
      "\n",
      "Correct:  The word for \"bag\" in Italian also begins with the letter \"B\". Do you remember?...... The word for \"bag\" is \"borsa\". \n",
      "\n",
      "\n",
      "past convo: Tutor: Please try to fill in the blank in Italian.  Student: il cane e dietro al scatora rosa\n",
      "\n",
      "\n",
      "Bot: almost but remember that the adjective comes after the noun . coniglio . . would be before the word letto . ! cane albero would be the correct\n",
      "\n",
      "\n",
      "Correct:  Remember that the word for \"box\" is \"scatola\".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 30\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "evaluate_with_target(encoder, decoder, searcher, voc, TEST_SIZE, INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
